\section{Existing Work}
\subsection{Driver Awareness}
Sleepiness can cause accidents in people’s daily lives (Cuentas \& Gonzales, 2017). Sleepiness affects activities that require short visual and motor reaction times such as driving a car. The highest number of accidents in these kinds of activities are vehicular accidents according to World Health Organization (WHO). Eyelashes could be an indicator of sleepiness (Cuentas \& Gonzales, 2017). Through image processing, a good eye tracker will be able to detect eyelashes and eye movements in order to determine if a person is sleepy or not. Driver awareness and fatigue also shows that a driver is powerless to stay awake (Ahmed et. al., 2015). Advancements in technology in order to prevent accidents are a challenge (Ahmed et. al., 2015). Eye trackers are considered to be parts of these advancements. Fatigue is another factor in these vehicular accidents since it affects the focus and attention of the driver. It also affects the movements and decision making of the driver which makes it a serious problem in driver awareness. By being able to prevent and monitor the driver’s fatigue, there will be a huge reduction in the number of vehicular accidents (Cuentas \& Gonzales, 2017).

\subsection{Eye Tracking and its Applications}
Eye tracking gives information on where do people look and what they ignore. The concept of eye tracking is very basic but the process and implementation can be very diverse and complex (Punde et. al., 2017). Vision is the most important sense (Punde et. al., 2017). In this study, detecting the behavior of drivers when driving especially at night is vital. By using eye tracking technology, the driver’s focus, attention, and presence can be analyzed and studied. The eye trackers are important part of this study because it measure visual attention and has become an important research tool (Jadhav, 2017). The different eye tracker metrics are vital in studying the behavior of the drivers. These metrics include the gaze point, fixation, smooth pursuit and saccades. The gaze point is the basic unit of measuring eye movement. The fixation is a cluster of gaze points. The smooth pursuit is a slow eye movement that allows the eye to follow an object moving slowly. On the other hand, the saccade is a rapid eye movement between fixations. By knowing these metrics, the driver’s eye movements can be studied more. The slow and rapid eye movements of the drivers’ eyes can lead to various inferences and conclusions.
\newline 

Eye tracking is important in many aspects (Krafka et. al., 2016). The number of these aspects grow as technology advances. Even though there are so many aspects wherein eye tracking is applicable, it has yet to become an ubiquitous technology (Krafka et. al., 2016). Meaning, eye tracking technology is not yet widespread or being used globally unlike the technology of voice assistants and speech recognition. The application of eye tracking may range from human-computer interaction, medical diagnoses, psychological studies, and computer vision (Krafka et. al., 2016). It was strongly stated that the human gaze is the externally-observable indicator of human attention (Khosla, 2016). The use of eye tracking requires a device where it will be interfaced for it to reach its full capabilities and functionality. This technology does not require additional devices from users because it can be interfaced on devices that they already have such as mobile phones and computers (Krafka et. al., 2016). A convolutional neural network was interfaced to a mobile device. The results with and without calibration were compared. The results show that a prediction error of 1.34cm to 2.12cm can be obtained with calibration. Without calibration, the error goes up to 1.71cm and 2.53cm.
\newline 

Non-intrusive ways of integrating eye tracking with other devices are better than intrusive ways (Nguyen, 2009). It is because non-intrusive ways do not require devices that cause distraction and annoyance to the user. Intrusive ways include using wearables such as headgears with cameras. On the other hand, non-intrusive ways of eye tracking include having a camera that is from a specific distance away from the user. There were three methods used in predicting eye gaze. These methods include detection using Haar-based features, Lucas Kanade method for tracking eye, and Gaussian process. The Haar-based method used thousands of samples of views and trains classifiers to detect object rapidly (Nguyen, 2009). On the other hand, the Lucas Kanade method uses set of pyramid representations of the original image and use the conventional tracking algorithm for each image pyramid (Nguyen, 2009). Lastly, the Gaussian process was used in eye tracking in such a way that given the gaze data of the user, the mean and covariance of these functions will be used to make predictions. (Nguyen, 2009).

\subsection{Eye Tracking using Different Cameras (RGB-D and Webcam)}
Eye gaze tracking systems are usually based on the use of infrared lights. However, such systems may not work outdoor or may have a very limited head box for them to work (Xiong et, al., 2014). This research paper proposes a non-infrared based approach in order to track the eyes with the use of an RGBD camera using Kinect. Their method uses a personalized 3D face model. The system tracks the center of the iris and a set of 2D facial landmarks whose 3D locations are provided by the camera. (Xiong et, al., 2014). They used a non-IR based method because there are less-strict requirements for hardware and it is easier to integrate with laptops and tablets (Xiong et, al., 2014). Without the use of IR lighting, the visibility of the pupils were decreased, so they replace the task of pupil detection with iris detection. They compared the performance of using RGB from using RGBD and found out that there is more accurate tracking in RGBD. However, the results of their non-IR based method are not as accurate as the ones from the IR based approach. 
\newline

The only RGB-D device used in this project is a Kinect sensor for gaze estimation for humans. The Kinect is set with a head coordinate system where the pupil center is detected from the image. The next step then involves calibration of the eyeball center where the system requests the human to gaze at a position creating a 3D eye model. The direction of the eye gaze is computed with the obtained calibrated eyeball center and pupil center. In their proposed method, it involves three main steps namely the face pose estimation, pupil center estimation, eyeball center calibration, and gaze estimation. The face pose estimation method uses the algorithm provided by Microsoft Kinect where additional devices are not needed to be able to estimate the head pose correctly. In pupil center estimation, an algorithm done by Febian Timm and Erhardt Barth is used that locates the pupil center by assuming that the pupil center P and the eyeball center C is a constant K. The eyeball center calibration is done by having two vectors: the target and the pupil center where the angle is obtained and these parameters are inputted to the given equation to calculate the eyeball center calibration. Lastly, the gaze estimation is obtained by the given parameters from the first three methods mentioned. Their project worked well with minimal error on the accuracy of the algorithm on detecting pupil center. (Jianfeng \& Shigang, 2014).
\newline

In this research, they implemented an eye ball tracking system for patients that cannot perform any voluntary tasks related to daily life. A real time data stream of the eye movement is captured using a webcam that transfers data serially to MATLAB. (Mazhar et, al., 2015). After that, a sequential image processing scheme segments the iris of the eye and calculates the centroid. Their idea was to create a general eye tracking tool that can be interfaced with wheelchairs, moveable patient beds, alerting mechanisms for disabled ones etc. (Mazhar et, al., 2015). The hardware that they used was a webcam by Logitech which can be interfaced serially using a USB port of a computer. This method involves an intrusive system because the camera is mounted to a headband. Their eye detection algorithm involved image acquisition through the use of the webcam, then plane separation which is the RGB plane, then thresholding (segmentation), then open binary image, then structuring, then dilation, and finally centroid calculation.

\subsection{Eye Tracking Applied  on Driver’s Awareness and Eye Behavior}
Road accidents have been prevalent in India and has shown consistency in increasing each year. The highest percentage as to why road accidents occur are due to the drivers themselves. This project aims to determine driver drowsiness by using a webcam in determining the eye blinking action of the driver using an algorithm that is implemented using cascade object identifier from vision toolbox of MATLAB. Their system will take the recorded video intro frames where these frames are then processed one by one, which results to a more accurate eye detection as oppose to eye tracking. To calculate the eye blinking, they have used an equation to calculate average drowsiness, number of closed eye found over number of frames; A closed eye would equate to zero eye blinking and one if the eyes are partially or fully open. If the percentage of drowsiness is set to be more than the threshold value, an alert signal will be generated to the driver. Two systems were used to test the research: System I: Inspirion 15 (DELL), core i3 processor (64bit) with 4GB of RAM, VGA inbuilt web cam, MATLAB 13; and System II: Inspiron 15 (DELL), core 13 processor (64bit) with 8GB of RAM, 3 MP USB web cam, MATLAB 13. About 1000 frames are processed online and 1500 frames are processed offline; while both systems show efficient results in overall drowsiness detection, System II has showed a more promising result as compared to System I. (Ahman \& Borole, 2015).
\newline

The objective of the project is to be able to simultaneously observe closed eyes and open mouth, when positive for yawning, the driver is alerted with a buzzer. A real-time video is captured by placing a camera in front of the driver using OpenCv, Viola Jones Algorithm, and Contour finding Algorithm are used in face detection. There are multiple detections considered in their system but the four main steps are as follows: face and eye detection, eye blinking detection, mouth detection, and warning system design. To detect face and eyes, they have used Viola Jones and Region of Interest (ROI) to locate the eyes. In eye blinking detection, the researchers only considered detecting the right eye in assumption that both eyes blink at the same time. The method used to get the eye blinking rate uses a ring buffer that calculates eye blinking rate every after first 100 first frames, writing 1 to the buffer when eye blinking is detected and 0 if otherwise. When the mouth is detected, decision of yawning is done by obtaining the difference between largest and smallest Y-coordinate values from the mouth; If the height surpasses the given threshold, the person is yawning. Their experiment lasted for 20 days that is divided into 6 sections: morning, afternoon, a given critical time, evening, night, and another given critical time. They also tested this on different test subjects based on sexuality, a person having or not having a mustaches and/or glasses, and age, giving a general best time result to use the system for each test subject.


\subsection{Eye Tracking Implementation using Microcontrollers}
The proposed system for eye tracking is implemented in real time using an arduino uno microcontroller and a zigbee wireless device. (Venugopal et, al., 2016). Two types of infrared eye following procedures are used which are enhanced pupil and dim pupil. Their system consists of three general modules. The first module consists of eye tracking and detection in real time using Viola-jones algorithm. The second module involves the detection of the pupils using Hough transformation. The third module  comprises the detection and tracking of the pupils and setting a direction. The obtained direction is sent to the Arduino with a wireless zigbee device for transmission of data. (Venugopal et, al., 2016). Basically, the three modules consists of image pre-processing, pupil region detection and pupil detection with movement detection. 
\newline

The main goal of developing the driver monitoring system using eye gaze tracking is to reduce road accidents and improve road safety. The algorithm detects the drowsiness of the driver and alerts the user using sound and vibration from steering. (Mavely et, al., 2016). The control of the whole framework operation is based on the Raspberry Pi 2. The project uses a Logitech c270 HD webcam and an LED IR illuminator for capturing an image. The camera is connected to the Pi using a USB port and it is placed above the steering wheel. An IR illumination is used to capture the user’s eyes during the night. For eye gaze tracking, CAMSHIFT (Continuously Adaptive Mean Shift) algorithm was used to extract the ROI (Region of Interest). The subject’s drowsiness was detected if the eye gaze is not detected more than 2 secs. Their proposed method was compared with other types of approaches and found out that their method was very cost effective with a high rate of speed and accuracy (Mavely et, al., 2016). They compared it with the bioelectric signal and driver face monitoring methods.

\subsection{Head Pose Estimation}
This research focuses on a real-time driver fatigue detection system using an RGB-D camera where visual cues such as head pose and eye state were used to detect driver drowsiness. They did the 3D head pose estimation by making use of the RGB-D data caught by the camera. If the driver’s head is not in its normal position for a long period of time or it happens frequently , then it will conclude that the driver is drowsy.  An alarm is used to alert the driver after detecting driver fatigue. They also used eye states to further increase the accuracy of driver fatigue detection. In order to detect eye states, they used WLBP (Weber Local Binary Pattern) which is a local image descriptor. The performance of eye state detection was evaluated by collecting eye image samples from the RPI ISL Eye Training Database. After obtaining the data for the head pose and eye states, they used a support vector machine (SVM) in order to classify data for correct detection of driver fatigue. The combination of head pose and eye state has proven to increase the effectiveness of the system.


Another method for head pose estimation is to use Active Appearance Models (AAM) and Pose from Orthography and Scaling with Iterations (POSIT) (Dongare \& Shah, 2017). AAM is an object model that is composed of statistical data based on the shape and texture of the object. The AAM will produce a 2D model of the head pose based on its algorithm. However, 2D models are not totally accurate that is why POSIT will be used to generate 3D models (Dongare \& Shah, 2017).


\section{Lacking in the Approaches}
\subsection{Eye Tracking and its Applications}
  For the implementation done by Krafka et. al., eye tracking technology were only integrated to mobile devices. This means that the implementation used a small form factor camera that can only be integrated to small devices like mobile phones. Using GazeCapture as its database, the data is from crowdsourcing (Krafka et. al., 2016). Crowdsourcing was used in order to deviate from prior works which made use of original data from cameras included in their eye trackers. The advantage of having a large database is that models can be tested repetitively for robustness (Krafka et. al., 2016). The eye tracker used  showed results before and after its calibration. The algorithm used in this specific eye tracker can only be used if the data is from a given database. However, Krafka (2016) strongly stated that this eye tracker outperformed state-of-the-art eye trackers by a large margin.
\newline

An introduction made by Punde et. al. (2017) shows that there are two types of eye trackers. These types include remote or screen based eye trackers and head-mounted or mobile eye tracker. The remote eye tracker requires the user to sit in front of the screen to interact with screen based content. On the other hand, head-mounted eye trackers does not distract users and lets them move freely. From their study, there are no direct applications per type of eye trackers and generalizations about both types of eye trackers were presented. This study was included in our research because of applications in automotives industry. Based on the eye trackers’ data, industries may improve their current products and devices. In addition, the visual data may be used for the industries’ analysis of eye movements and behaviors of users such as those of the psychological and medical applications (Punde et. al., 2017). This study is a helpful overview of eye tracking and its applications to different fields and practices. Even though there are no specific target field, the overall use, functionality, advantages, and disadvantages of eye trackers were presented clearly.
\newline

\subsection{Head Pose Estimation}
Through computer vision techniques, the detection of eye state, head pose, and facial features are easier. However, in the study conducted by Liu (2015), facial features were not part of their parameters for driver fatigue. Even though computer vision techniques nowadays are more advanced, the accuracy of detecting eye state and head pose is not guaranteed due to different illumination conditions and various facial features for different persons (Liu et. al, 2015). In addition, other facial actions were not taken into consideration in this study such as yawning or when the person being tested and monitored has face disorders that make it difficult for the RGB-D sensor to capture accurate data. Moreover, head pose estimation is very dependent on the RGB-D sensor since an RGB sensor cannot have depth values. These values are substantial and beneficial in driver fatigue detection since it allows another visual cue to be analyzed. 


\section{Summary}

The proponents’ review of related literature were about eye-tracking technology, head pose estimation, and driver awareness. Driver awareness refers to the focus, attention, and functionality of the driver. Sleepiness and fatigue were considered to be major factors in vehicular accidents. The number of accidents can be minimized when these factors are being monitored using advancements in technology such as eye trackers and fatigue detectors.  In the applications of eye tracking, it was discussed that eye tracking can be used to help persons with disabilities, to study the psychology of people, and to interact with computers easily. In the usage of RGB-D camera/webcam, their differences were seen by their quality of RGBD detection. In the utilization of driver’s eye behavior in eye tracking, it was researched that there were studies to measure driver alertness and it can be based to make an effective eye tracking device for drivers. Lastly, the implementation of eye trackers using microcontrollers were dealt with because the proponents want to focus on having a lighter and compact device for eye detection rather than having laptops/computers as the brains of the eye tracking device. The literatures about these involved different types of microcontrollers like arduino/raspberry pi that were used to implement the eye tracking device. For head pose estimation, the use of an RGB-D sensor was emphasized to ensure that disadvantages of an RGB sensor will be compensated. By using an RGB-D sensor for head pose estimation, different illumination conditions will have the least effect on the captured images such as having depth values will make it easier detecting facial features. Having head pose estimation as another visual cue for driver fatigue is vital in having more accurate data and reduction of false alarms due to errors in data gathering. In addition by using WLBP for the images, the effectiveness and robustness were emphasized because the results showed that WLBP is better than other image descriptors. Moreover, the head pose helped in classifying the fatigue levels of the driver using a support vector machine (SVM). 




